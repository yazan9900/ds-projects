{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions_DF = pd.read_csv('emotion.txt', delimiter=';',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions_DF.rename(columns={0:'Sentence',1:'Emotion'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions_DF.Emotion.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data = Emotions_DF, x = 'Emotion')\n",
    "plt.title('Emotion',fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "Emotions_DF.groupby('Emotion').size().plot.pie(autopct='%.2f', textprops={'fontsize': 16})\n",
    "plt.title('Emotion',fontsize=20)\n",
    "plt.ylabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'joy':0.3351,'love':0.0815,'sadness':0.2916,'surprise':0.0358,'anger':0.1349,'fear':0.1211}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emo in Emotions_DF.Emotion.unique():\n",
    "    print('Average of sentence length of {} : {}'.format(emo, Emotions_DF.query('Emotion == \"{}\"'.format(emo)).Sentence.apply(lambda x :len(x)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops=['the','and','that','for','with','this','for','was','you','about']\n",
    "\n",
    "for emotion in Emotions_DF.Emotion.unique():\n",
    "    Data=' '.join(Emotions_DF[Emotions_DF['Emotion']==emotion]['Sentence'].values)\n",
    "    tokens =[word.lower() for word in Data.split() if len(word)>6 and word.lower() not in stops ]\n",
    "    dictWords=Counter(tokens).most_common(20)\n",
    "    Words=[i[0] for i in dictWords]\n",
    "    Freq=[i[1] for i in dictWords]\n",
    "    DF=pd.DataFrame({'Word':Words,'Freq':Freq})\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.barplot(x=DF['Word'][0:10],y=DF['Freq'][0:10])\n",
    "    plt.title(f'Most frequent words for {emotion} emotion')\n",
    "    plt.xticks(rotation=25, ha='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Emotions_DF['Sentence'], \n",
    "                                                    Emotions_DF['Emotion'], \n",
    "                                                    random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions_DF.loc[X_train.index, 'Train/Test'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions_DF.loc[X_test.index, 'Train/Test'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions_DF.groupby(['Emotion', 'Train/Test']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,2),stop_words='english').fit(X_train)\n",
    "X_train_vectorized = count_vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB(alpha=0.1)\n",
    "MNB.fit(X_train_vectorized, y_train)\n",
    "predictions = MNB.predict(count_vect.transform(X_test))\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(C=0.1)\n",
    "lsvc.fit(X_train_vectorized, y_train)\n",
    "predictions = lsvc.predict(count_vect.transform(X_test))\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_CM = confusion_matrix(y_test, predictions)\n",
    "lsvc_CM_DF = pd.DataFrame(lsvc_CM, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "lsvc_CM_DF.index.name = 'Actual'\n",
    "lsvc_CM_DF.columns.name = 'Predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(lsvc_CM_DF, fmt='g', annot=True, cmap='Blues')\n",
    "plt.title('Linear SVC predictions Confusion Matrix\\n',fontsize=20)\n",
    "plt.xlabel('\\nPredicted',fontsize=15)\n",
    "plt.ylabel('Actual',fontsize=15)\n",
    "plt.xticks(ha='center',fontsize=12)\n",
    "plt.yticks(fontsize=12, rotation =0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(ngram_range = (1,2),stop_words='english').fit(X_train)\n",
    "X_train_vectorized = tf_vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB(alpha=0.1)\n",
    "MNB.fit(X_train_vectorized, y_train)\n",
    "predictions = MNB.predict(tf_vect.transform(X_test))\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=100, solver='sag', class_weight='balanced', random_state=18)\n",
    "LR.fit(X_train_vectorized, y_train)\n",
    "predictions = LR.predict(tf_vect.transform(X_test))\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_CM = confusion_matrix(y_test, predictions)\n",
    "LR_CM_DF = pd.DataFrame(LR_CM, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "LR_CM_DF.index.name = 'Actual'\n",
    "LR_CM_DF.columns.name = 'Predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(LR_CM_DF, fmt='g', annot=True, cmap='YlOrBr')\n",
    "plt.title('Logistic Regression predictions Confusion Matrix\\n',fontsize=20)\n",
    "plt.xlabel('\\nPredicted',fontsize=15)\n",
    "plt.ylabel('Actual',fontsize=15)\n",
    "plt.xticks(ha='center',fontsize=12)\n",
    "plt.yticks(fontsize=12, rotation =0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_vect = HashingVectorizer(ngram_range=(1,2) ,stop_words='english').fit(X_train)\n",
    "X_train_vectorized = hash_vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNB = MultinomialNB(alpha=0.1)\n",
    "# MNB.fit(X_train_vectorized, y_train)\n",
    "# predictions = MNB.predict(hash_vect.transform(X_test))\n",
    "# accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=100, solver='sag', class_weight='balanced', random_state=18)\n",
    "LR.fit(X_train_vectorized, y_train)\n",
    "predictions = LR.predict(hash_vect.transform(X_test))\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_CM = confusion_matrix(y_test, predictions)\n",
    "LR_CM_DF = pd.DataFrame(LR_CM, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "LR_CM_DF.index.name = 'Actual'\n",
    "LR_CM_DF.columns.name = 'Predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(LR_CM_DF, fmt='g', annot=True, cmap='Greens')\n",
    "plt.title('Logistic Regression predictions Confusion Matrix\\n',fontsize=20)\n",
    "plt.xlabel('\\nPredicted',fontsize=15)\n",
    "plt.ylabel('Actual',fontsize=15)\n",
    "plt.xticks(ha='center',fontsize=12)\n",
    "plt.yticks(fontsize=12, rotation =0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(C=10, random_state=18)\n",
    "lsvc.fit(X_train_vectorized, y_train)\n",
    "predictions = lsvc.predict(hash_vect.transform(X_test))\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_CM = confusion_matrix(y_test, predictions)\n",
    "lsvc_CM_DF = pd.DataFrame(lsvc_CM, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "lsvc_CM_DF.index.name = 'Actual'\n",
    "lsvc_CM_DF.columns.name = 'Predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(lsvc_CM_DF, fmt='g', annot=True, cmap='Greys')\n",
    "plt.title('Linear SVC predictions Confusion Matrix\\n',fontsize=20)\n",
    "plt.xlabel('\\nPredicted',fontsize=15)\n",
    "plt.ylabel('Actual',fontsize=15)\n",
    "plt.xticks(ha='center',fontsize=12)\n",
    "plt.yticks(fontsize=12, rotation =0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=1048576, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_vectorized, pd.get_dummies(y_train),  epochs=10, verbose=1, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.epoch, model.history.history['loss'])\n",
    "plt.xlabel('epochs', fontsize=14)\n",
    "plt.ylabel('loss', fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.epoch, model.history.history['accuracy'])\n",
    "plt.xlabel('epochs', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(hash_vect.transform(X_test), pd.get_dummies(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
